{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-23T11:58:21.226957Z",
     "start_time": "2024-12-23T11:44:55.586941Z"
    }
   },
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "images_folder = \"C:/Users/atitk/PycharmProjects/230241_AtitKumarSatsangi_deeploycv/.venv/Cat\"\n",
    "images = os.listdir(images_folder)\n",
    "weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
    "model = models.resnet18(weights=weights)\n",
    "model.fc=nn.Identity()\n",
    "print(model)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "annoy_index=AnnoyIndex(512,'angular')\n",
    "for i in range(len(images)):\n",
    "    image = Image.open(os.path.join(images_folder, images[i]))\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    if input_tensor.size()[1] == 3:  # Check if the image has 3 channels (RGB)\n",
    "        output_tensor = model(input_tensor)\n",
    "        # predicted_class = torch.argmax(output_tensor)\n",
    "        # print(f'{images[i]} predicted as {weights.meta[\"categories\"][predicted_class]}')\n",
    "        annoy_index.add_item(i,output_tensor[0])\n",
    "\n",
    "        if i%100==0:\n",
    "            print(f'Processing image {i}')\n",
    "annoy_index.build(10)\n",
    "annoy_index.save('cat_index.ann')\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "Processing image 0\n",
      "Processing image 100\n",
      "Processing image 200\n",
      "Processing image 300\n",
      "Processing image 400\n",
      "Processing image 500\n",
      "Processing image 600\n",
      "Processing image 700\n",
      "Processing image 800\n",
      "Processing image 900\n",
      "Processing image 1000\n",
      "Processing image 1100\n",
      "Processing image 1200\n",
      "Processing image 1300\n",
      "Processing image 1400\n",
      "Processing image 1500\n",
      "Processing image 1600\n",
      "Processing image 1700\n",
      "Processing image 1800\n",
      "Processing image 1900\n",
      "Processing image 2000\n",
      "Processing image 2100\n",
      "Processing image 2200\n",
      "Processing image 2300\n",
      "Processing image 2400\n",
      "Processing image 2500\n",
      "Processing image 2600\n",
      "Processing image 2700\n",
      "Processing image 2800\n",
      "Processing image 2900\n",
      "Processing image 3000\n",
      "Processing image 3100\n",
      "Processing image 3200\n",
      "Processing image 3300\n",
      "Processing image 3400\n",
      "Processing image 3500\n",
      "Processing image 3600\n",
      "Processing image 3700\n",
      "Processing image 3800\n",
      "Processing image 3900\n",
      "Processing image 4000\n",
      "Processing image 4100\n",
      "Processing image 4200\n",
      "Processing image 4300\n",
      "Processing image 4400\n",
      "Processing image 4500\n",
      "Processing image 4600\n",
      "Processing image 4700\n",
      "Processing image 4800\n",
      "Processing image 4900\n",
      "Processing image 5000\n",
      "Processing image 5100\n",
      "Processing image 5200\n",
      "Processing image 5300\n",
      "Processing image 5400\n",
      "Processing image 5500\n",
      "Processing image 5600\n",
      "Processing image 5700\n",
      "Processing image 5800\n",
      "Processing image 5900\n",
      "Processing image 6000\n",
      "Processing image 6100\n",
      "Processing image 6200\n",
      "Processing image 6300\n",
      "Processing image 6400\n",
      "Processing image 6500\n",
      "Processing image 6600\n",
      "Processing image 6700\n",
      "Processing image 6800\n",
      "Processing image 6900\n",
      "Processing image 7000\n",
      "Processing image 7100\n",
      "Processing image 7200\n",
      "Processing image 7300\n",
      "Processing image 7400\n",
      "Processing image 7500\n",
      "Processing image 7600\n",
      "Processing image 7700\n",
      "Processing image 7800\n",
      "Processing image 7900\n",
      "Processing image 8000\n",
      "Processing image 8100\n",
      "Processing image 8200\n",
      "Processing image 8300\n",
      "Processing image 8400\n",
      "Processing image 8500\n",
      "Processing image 8600\n",
      "Processing image 8700\n",
      "Processing image 8800\n",
      "Processing image 8900\n",
      "Processing image 9000\n",
      "Processing image 9100\n",
      "Processing image 9200\n",
      "Processing image 9300\n",
      "Processing image 9400\n",
      "Processing image 9500\n",
      "Processing image 9600\n",
      "Processing image 9700\n",
      "Processing image 9800\n",
      "Processing image 9900\n",
      "Processing image 10000\n",
      "Processing image 10100\n",
      "Processing image 10200\n",
      "Processing image 10300\n",
      "Processing image 10400\n",
      "Processing image 10500\n",
      "Processing image 10600\n",
      "Processing image 10700\n",
      "Processing image 10900\n",
      "Processing image 11000\n",
      "Processing image 11100\n",
      "Processing image 11200\n",
      "Processing image 11300\n",
      "Processing image 11400\n",
      "Processing image 11500\n",
      "Processing image 11600\n",
      "Processing image 11700\n",
      "Processing image 11800\n",
      "Processing image 11900\n",
      "Processing image 12000\n",
      "Processing image 12100\n",
      "Processing image 12200\n",
      "Processing image 12300\n",
      "Processing image 12400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:46:33.586374Z",
     "start_time": "2024-12-23T12:02:09.471859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image,ImageDraw\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "from annoy import AnnoyIndex\n",
    "weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
    "model = models.resnet18(weights=weights)\n",
    "model.fc=nn.Identity()\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "annoy_index=AnnoyIndex(512,'angular')\n",
    "annoy_index.load('cat_index.ann')\n",
    "image_grid=Image.new('RGB',(1000,1000))\n",
    "for i in range(len(images)):\n",
    "    image = Image.open(os.path.join(images_folder, images[i]))\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    if input_tensor.size()[1] == 3:  # Check if the image has 3 channels (RGB)\n",
    "        output_tensor = model(input_tensor)\n",
    "        nns=annoy_index.get_nns_by_vector(output_tensor[0],24)\n",
    "        image=image.resize((200,200))\n",
    "        image_draw=ImageDraw.Draw(image)\n",
    "        image_draw.rectangle([(0,0),(199,199)],outline='red',width=8)\n",
    "        image_grid.paste(image,((0,0)))\n",
    "\n",
    "        for j in range(24):\n",
    "            search_image=Image.open(os.path.join(images_folder, images[nns[j]]))\n",
    "            search_image=search_image.resize((200,200))\n",
    "            image_grid.paste(search_image,((200*((j+1)%5),200*((j+1)//5))))\n",
    "        image_grid.save(f\"ImageDump/image{i}.png\")\n"
   ],
   "id": "6f5ed00d0ca79759",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\ImageFile.py:536\u001B[0m, in \u001B[0;36m_save\u001B[1;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 536\u001B[0m     fh \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfileno\u001B[49m()\n\u001B[0;32m    537\u001B[0m     fp\u001B[38;5;241m.\u001B[39mflush()\n",
      "\u001B[1;31mAttributeError\u001B[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 35\u001B[0m\n\u001B[0;32m     33\u001B[0m     search_image\u001B[38;5;241m=\u001B[39msearch_image\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;241m200\u001B[39m,\u001B[38;5;241m200\u001B[39m))\n\u001B[0;32m     34\u001B[0m     image_grid\u001B[38;5;241m.\u001B[39mpaste(search_image,((\u001B[38;5;241m200\u001B[39m\u001B[38;5;241m*\u001B[39m((j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m5\u001B[39m),\u001B[38;5;241m200\u001B[39m\u001B[38;5;241m*\u001B[39m((j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m5\u001B[39m))))\n\u001B[1;32m---> 35\u001B[0m \u001B[43mimage_grid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mImageDump/image\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.png\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:2459\u001B[0m, in \u001B[0;36mImage.save\u001B[1;34m(self, fp, format, **params)\u001B[0m\n\u001B[0;32m   2456\u001B[0m         fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw+b\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2458\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2459\u001B[0m     \u001B[43msave_handler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2460\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   2461\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m open_fp:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\PngImagePlugin.py:1412\u001B[0m, in \u001B[0;36m_save\u001B[1;34m(im, fp, filename, chunk, save_all)\u001B[0m\n\u001B[0;32m   1408\u001B[0m     im \u001B[38;5;241m=\u001B[39m _write_multiple_frames(\n\u001B[0;32m   1409\u001B[0m         im, fp, chunk, rawmode, default_image, append_images\n\u001B[0;32m   1410\u001B[0m     )\n\u001B[0;32m   1411\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im:\n\u001B[1;32m-> 1412\u001B[0m     \u001B[43mImageFile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_idat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrawmode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info:\n\u001B[0;32m   1415\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m info_chunk \u001B[38;5;129;01min\u001B[39;00m info\u001B[38;5;241m.\u001B[39mchunks:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\ImageFile.py:540\u001B[0m, in \u001B[0;36m_save\u001B[1;34m(im, fp, tile, bufsize)\u001B[0m\n\u001B[0;32m    538\u001B[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, io\u001B[38;5;241m.\u001B[39mUnsupportedOperation) \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m--> 540\u001B[0m     \u001B[43m_encode_tile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflush\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    542\u001B[0m     fp\u001B[38;5;241m.\u001B[39mflush()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\ImageFile.py:559\u001B[0m, in \u001B[0;36m_encode_tile\u001B[1;34m(im, fp, tile, bufsize, fh, exc)\u001B[0m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exc:\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;66;03m# compress to Python file-compatible object\u001B[39;00m\n\u001B[0;32m    558\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 559\u001B[0m         errcode, data \u001B[38;5;241m=\u001B[39m \u001B[43mencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbufsize\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    560\u001B[0m         fp\u001B[38;5;241m.\u001B[39mwrite(data)\n\u001B[0;32m    561\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m errcode:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ded9a4eb7b98293"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
